{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfb5955hEOxyWexD3PiAwv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kingsley-Yoimiya/cuda-learning/blob/main/simple_practice/CUDA_TEST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add nvcc support for jupyter\n",
        "!pip install nvcc4jupyter\n",
        "\n",
        "%load_ext nvcc4jupyter\n",
        "\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ie07XVaXVglG",
        "outputId": "908d6b9a-6c66-4a50-da9e-9ad8022da2b6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpuw4_udth\".\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <chrono>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <cuda.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define BLOCK_SIZE 256\n",
        "\n",
        "__global__ void reduce_sum_kernel(const float* input_vecs, size_t n, size_t dim, float* output_vec) {\n",
        "    size_t idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(idx < n * dim) {\n",
        "        atomicAdd(&output_vec[idx % dim], input_vecs[idx]);\n",
        "    }\n",
        "}\n",
        "\n",
        "void reduce_sum(const float* input_vecs, size_t n, size_t dim, float* output_vec) {\n",
        "    float* cu_input_vecs;\n",
        "    float* cu_output_vecs;\n",
        "    size_t input_size = n * dim * sizeof(float), output_size = dim * sizeof(float);\n",
        "    cudaMalloc((void**) &cu_input_vecs, input_size);\n",
        "    cudaMalloc((void**) &cu_output_vecs, output_size);\n",
        "    cudaMemcpy(cu_input_vecs, input_vecs, input_size, cudaMemcpyHostToDevice);\n",
        "    cudaMemset(cu_output_vecs, 0, output_size);\n",
        "    size_t grid_size = (n * dim + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    reduce_sum_kernel <<< grid_size, BLOCK_SIZE >>>(cu_input_vecs, n, dim, cu_output_vecs);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemcpy(output_vec, cu_output_vecs, output_size, cudaMemcpyDeviceToHost);\n",
        "    cudaFree(cu_input_vecs);\n",
        "    cudaFree(cu_output_vecs);\n",
        "}\n",
        "\n",
        "const long long N = 1e9;\n",
        "const int T = 1000;\n",
        "\n",
        "uniform_real_distribution<float> u(0, 1);\n",
        "mt19937 rnd(chrono::system_clock::now().time_since_epoch().count());\n",
        "\n",
        "int main() {\n",
        "    float* input_vecs = new float[N];\n",
        "    float* output_vec = new float[T];\n",
        "    float* correct_vec = new float[T];\n",
        "    for(int i = 0; i < N; i++) {\n",
        "        input_vecs[i] = u(rnd);\n",
        "    }\n",
        "\n",
        "    cerr << \"GENERATE OK!\" << endl;\n",
        "    double st = clock();\n",
        "    reduce_sum(input_vecs, N / T, T, output_vec);\n",
        "    double ed = clock();\n",
        "    std::cout << (ed - st) / CLOCKS_PER_SEC << std::endl;\n",
        "\n",
        "    st = clock();\n",
        "\n",
        "    for(int i = 0; i < T; i++) {\n",
        "        correct_vec[i] = 0;\n",
        "    }\n",
        "    for(int i = 0; i < N; i++) {\n",
        "        correct_vec[i % T] += input_vecs[i];\n",
        "    }\n",
        "\n",
        "    ed = clock();\n",
        "    std::cout << (ed - st) / CLOCKS_PER_SEC << std::endl;\n",
        "\n",
        "    for(int i = 0; i < T; i++) {\n",
        "        if(abs(correct_vec[i] - output_vec[i]) > 1) {\n",
        "            std::cout << correct_vec[i] << \" \" << output_vec[i] << \" ERROR!\" << std::endl;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << output_vec[0] << std::endl;\n",
        "    delete[] input_vecs;\n",
        "    delete[] output_vec;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW1lsLB3MMya",
        "outputId": "bc57ecda-20da-4fb7-f72d-feacaf805188"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATE OK!\n",
            "0.991417\n",
            "3.25612\n",
            "500030\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <chrono>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <cuda.h>\n",
        "#include <assert.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define GRID_SIZE 128\n",
        "#define BLOCK_SIZE 512\n",
        "#define cudaCheckError() {                                                      \\\n",
        "    cudaError_t err = cudaGetLastError();                                       \\\n",
        "    if (err != cudaSuccess) {                                                   \\\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err)                  \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl;        \\\n",
        "        exit(EXIT_FAILURE);                                                     \\\n",
        "    }                                                                           \\\n",
        "}\n",
        "#define cudaCheckErrorSync() {                                                  \\\n",
        "    cudaDeviceSynchronize();                                                    \\\n",
        "    cudaError_t err = cudaGetLastError();                                       \\\n",
        "    if (err != cudaSuccess) {                                                   \\\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err)                  \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl;        \\\n",
        "        exit(EXIT_FAILURE);                                                     \\\n",
        "    }                                                                           \\\n",
        "}\n",
        "\n",
        "#define cudaCheckErrorSync() {}\n",
        "#define cudaCheckError() {}\n",
        "\n",
        "__global__ void matmul_kernel(const float* A, const float* B, size_t n, size_t m, size_t k, float* output) {\n",
        "    size_t idi = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    size_t idj = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if(idi < n && idj < k) {\n",
        "        float res = 0;\n",
        "        for(int idk = 0; idk < m; idk++) {\n",
        "            res += A[idi * m + idk] * B[idk * k + idj];\n",
        "        }\n",
        "        output[idi * k + idj] = res;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matmul(const float* A, const float* B, size_t n, size_t m, size_t k, float* output) {\n",
        "    float* cu_A;\n",
        "    float* cu_B;\n",
        "    float* cu_output;\n",
        "    size_t A_size = n * m * sizeof(float), B_size = m * k * sizeof(float), out_size = n * k * sizeof(float);\n",
        "    cudaMalloc((void**) &cu_A, A_size);\n",
        "    cudaCheckError();\n",
        "    cudaMalloc((void**) &cu_B, B_size);\n",
        "    cudaMalloc((void**) &cu_output, out_size);\n",
        "    cudaCheckError();\n",
        "    cudaMemcpy(cu_A, A, A_size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cu_B, B, B_size, cudaMemcpyHostToDevice);\n",
        "    cudaCheckError();\n",
        "    cudaMemset(cu_output, 0, out_size);\n",
        "    dim3 grid(GRID_SIZE, GRID_SIZE);\n",
        "    dim3 block((n + GRID_SIZE - 1) / GRID_SIZE, (k + GRID_SIZE - 1) / GRID_SIZE);\n",
        "    cerr << (n + GRID_SIZE - 1) / GRID_SIZE << \" \" << (k + GRID_SIZE - 1) / GRID_SIZE << endl;\n",
        "    matmul_kernel <<< grid, block >>>(cu_A, cu_B, n, m, k, cu_output);\n",
        "    cudaCheckErrorSync();\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemcpy(output, cu_output, out_size, cudaMemcpyDeviceToHost);\n",
        "    cudaCheckError();\n",
        "    cudaFree(cu_A);\n",
        "    cudaFree(cu_B);\n",
        "    cudaFree(cu_output);\n",
        "}\n",
        "\n",
        "const int N = 4096, M = 4096, K = 4096;\n",
        "const int T = 100;\n",
        "\n",
        "uniform_real_distribution<float> u(0, 1);\n",
        "mt19937 rnd(chrono::system_clock::now().time_since_epoch().count());\n",
        "\n",
        "int main() {\n",
        "    float* A = new float[N * M];\n",
        "    float* B = new float[M * K];\n",
        "    float* C = new float[N * K];\n",
        "    float* D = new float[N * K];\n",
        "    for(int i = 0; i < N * M; i++) {\n",
        "        A[i] = u(rnd);\n",
        "    }\n",
        "    for(int i = 0; i < M * K; i++) {\n",
        "        B[i] = u(rnd);\n",
        "    }\n",
        "    cerr << \"GENERATE OK!\" << endl;\n",
        "\n",
        "    double st = clock();\n",
        "    matmul(A, B, N, M, K, C);\n",
        "    double ed = clock();\n",
        "    std::cout << (ed - st) / CLOCKS_PER_SEC << std::endl;\n",
        "\n",
        "    st = clock();\n",
        "    for(int i = 0; i < N * K; i++) {\n",
        "        D[i] = 0;\n",
        "    }\n",
        "    for(int i = 0; i < N; i++) {\n",
        "       for(int j = 0; j < M; j++) {\n",
        "            for(int k = 0; k < K; k++) {\n",
        "                D[i * K + k] += A[i * M + j] * B[j * K + k];\n",
        "            }\n",
        "       }\n",
        "    }\n",
        "\n",
        "    ed = clock();\n",
        "    std::cout << (ed - st) / CLOCKS_PER_SEC << std::endl;\n",
        "\n",
        "    for(int i = 0; i < N * K; i++) {\n",
        "        if(fabs(C[i] - D[i]) > 1e-2) {\n",
        "            std::cout << C[i] << \" \" << D[i] << \" ERROR!\" << std::endl;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"RESULT: \" << C[0] << std::endl;\n",
        "    delete[] A;\n",
        "    delete[] B;\n",
        "    delete[] C;\n",
        "    delete[] D;\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rnuJHlWXzZS",
        "outputId": "43d10c04-255a-42d5-edbe-5d95f6bd5b81"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATE OK!\n",
            "32 32\n",
            "2.62281\n",
            "297.349\n",
            "RESULT: 1023.66\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <iostream>\n",
        "#include <random>\n",
        "#include <chrono>\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <cuda.h>\n",
        "#include <assert.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define GRID_SIZE 128\n",
        "#define BLOCK_SIZE 256\n",
        "#define BATCH 131072\n",
        "#define cudaCheckError() {                                                      \\\n",
        "    cudaError_t err = cudaGetLastError();                                       \\\n",
        "    if (err != cudaSuccess) {                                                   \\\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err)                  \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl;        \\\n",
        "        exit(EXIT_FAILURE);                                                     \\\n",
        "    }                                                                           \\\n",
        "}\n",
        "#define cudaCheckErrorSync() {                                                  \\\n",
        "    cudaDeviceSynchronize();                                                    \\\n",
        "    cudaError_t err = cudaGetLastError();                                       \\\n",
        "    if (err != cudaSuccess) {                                                   \\\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err)                  \\\n",
        "                  << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl;        \\\n",
        "        exit(EXIT_FAILURE);                                                     \\\n",
        "    }                                                                           \\\n",
        "}\n",
        "\n",
        "// #define cudaCheckErrorSync() {}\n",
        "// #define cudaCheckError() {}\n",
        "\n",
        "int nextPow2(int x) {\n",
        "    x--;\n",
        "    for(int i = 1; i < 32; i <<= 1) x |= x >> i;\n",
        "    return x + 1;\n",
        "}\n",
        "\n",
        "__global__ void debubble_kernel_1(const int *a, int n, int *blockpre, int *store) {\n",
        "    __shared__ int s[BLOCK_SIZE];\n",
        "    int st = (blockIdx.x * blockDim.x + threadIdx.x) * BATCH, ed = st + BATCH;\n",
        "    int blockid = blockIdx.x;\n",
        "    int cnt = 0;\n",
        "    for(int i = min(st, n); i < min(ed, n); i++) cnt += a[i] != 0;\n",
        "    s[threadIdx.x] = store[blockIdx.x * blockDim.x + threadIdx.x] = cnt;\n",
        "    __syncthreads();\n",
        "    for(int i = 1; i < blockDim.x; i <<= 1) {\n",
        "        if(threadIdx.x + i < blockDim.x) s[threadIdx.x + i] += s[threadIdx.x];\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x == 0) blockpre[blockid] = s[blockDim.x - 1];\n",
        "}\n",
        "\n",
        "__global__ void debubble_kernel_2(const int *a, int n, const int *blockpre, const int *store, int *output) {\n",
        "    __shared__ int s[BLOCK_SIZE];\n",
        "    int st = (blockIdx.x * blockDim.x + threadIdx.x) * BATCH, ed = st + BATCH;\n",
        "    int cnt = store[blockIdx.x * blockDim.x + threadIdx.x];\n",
        "    //for(int i = min(st, n); i < min(ed, n); i++) cnt += a[i] != 0;\n",
        "    s[threadIdx.x] = cnt;\n",
        "    __syncthreads();\n",
        "    for(int i = 1, totnum = blockDim.x >> 1; i < blockDim.x; i <<= 1, totnum >>= 1) {\n",
        "        if(threadIdx.x < totnum) {\n",
        "            int id1 = threadIdx.x * (i << 1) + i - 1, id2 = id1 + i;\n",
        "            s[id2] += s[id1];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x == 0) s[blockDim.x - 1] = 0;\n",
        "    for(int i = blockDim.x >> 1, totnum = 1; i > 0; i >>= 1, totnum <<= 1) {\n",
        "        if(threadIdx.x < totnum) {\n",
        "            int id1 = threadIdx.x * (i << 1) + i - 1, id2 = id1 + i;\n",
        "            int tmp = s[id1];\n",
        "            s[id1] = s[id2];\n",
        "            s[id2] += tmp;\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    cnt = s[threadIdx.x] + blockpre[blockIdx.x];\n",
        "    for(int i = min(st, n); i < min(ed, n); i++) {\n",
        "        if(a[i] != 0) {\n",
        "            output[cnt] = a[i];\n",
        "            cnt++;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void preSum(int *a, int tot, size_t *ans) {\n",
        "    __shared__ int s[BLOCK_SIZE];\n",
        "    s[threadIdx.x] = a[threadIdx.x];\n",
        "    __syncthreads();\n",
        "    for(int i = 1, totnum = blockDim.x >> 1; i < blockDim.x; i <<= 1, totnum >>= 1) {\n",
        "        if(threadIdx.x < totnum) {\n",
        "            int id1 = threadIdx.x * (i << 1) + i - 1, id2 = id1 + i;\n",
        "            s[id2] += s[id1];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if(threadIdx.x == 0) ans[0] = s[blockDim.x - 1], s[blockDim.x - 1] = 0;\n",
        "    for(int i = blockDim.x >> 1, totnum = 1; i > 0; i >>= 1, totnum <<= 1) {\n",
        "        if(threadIdx.x < totnum) {\n",
        "            int id1 = threadIdx.x * (i << 1) + i - 1, id2 = id1 + i;\n",
        "            int tmp = s[id1];\n",
        "            s[id1] = s[id2];\n",
        "            s[id2] += tmp;\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    a[threadIdx.x] = s[threadIdx.x];\n",
        "}\n",
        "\n",
        "size_t debubble(vector < int >&a) {\n",
        "    int* cu_a;\n",
        "    int* blockpre;\n",
        "    int* output;\n",
        "    int *store;\n",
        "    int n = a.size(), totcore = (n + BATCH - 1) / BATCH, blocknum = nextPow2((totcore + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "    cout << totcore << \" \" << blocknum << endl;\n",
        "    cudaMalloc((void**) &cu_a, n * sizeof(int));\n",
        "    cudaCheckError();\n",
        "    cudaMalloc((void**) &blockpre, (blocknum) * sizeof(int));\n",
        "    cudaMalloc((void**) &output, n * sizeof(int));\n",
        "    cudaMalloc((void**) &store , blocknum * BLOCK_SIZE * sizeof(int));\n",
        "    cudaMemcpy(cu_a, a.data(), n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaCheckError();\n",
        "    cudaMemset(blockpre, 0, (blocknum)  * sizeof(int));\n",
        "    cudaMemset(output, 0, n * sizeof(int));\n",
        "    cudaMemset(store, 0, blocknum * BLOCK_SIZE * sizeof(int));\n",
        "    cudaCheckError();\n",
        "    // cout << \"!\" << endl;\n",
        "    debubble_kernel_1 <<< blocknum, BLOCK_SIZE >>>(cu_a, n, blockpre, store);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaCheckError();\n",
        "    // cout << \"!1\" << \" \" << blocknum << endl;\n",
        "\n",
        "    // illigal:\n",
        "    // for(int i = 1; i < blocknum; i++) cout << i << endl, blockpre[i] += blockpre[i - 1];\n",
        "    size_t * cu_ans, ans;\n",
        "    cudaMalloc((void**) &cu_ans, sizeof(size_t));\n",
        "    preSum <<< 1, blocknum >>> (blockpre, blocknum, cu_ans);\n",
        "    cudaMemcpy(&ans, cu_ans, sizeof(size_t), cudaMemcpyDeviceToHost);\n",
        "    // cout << \"!2\" << \" \" << ans << endl;\n",
        "    cudaCheckError();\n",
        "    debubble_kernel_2 <<< blocknum, BLOCK_SIZE >>>(cu_a, n, blockpre, store, output);\n",
        "    cudaCheckError();\n",
        "    cudaDeviceSynchronize();\n",
        "    // cout << \"!3\" << endl;\n",
        "    cudaCheckError();\n",
        "    // cout << \"!\" << endl;\n",
        "    cudaMemcpy(a.data(), output, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaCheckError();\n",
        "    // cout << \"!\" << endl;\n",
        "    cudaFree(cu_a);\n",
        "    cudaFree(blockpre);\n",
        "    cudaFree(output);\n",
        "    cudaCheckError();\n",
        "    return ans;\n",
        "}\n",
        "\n",
        "const int N = 536870912, M = 2000, K = 2000;\n",
        "const int T = 100;\n",
        "\n",
        "uniform_real_distribution<float> u(0, 1);\n",
        "mt19937 rnd(chrono::system_clock::now().time_since_epoch().count());\n",
        "\n",
        "int main() {\n",
        "    vector < int > a, b, c;\n",
        "    for(int i = 0; i < N; i++) {\n",
        "        a.emplace_back(rnd() % 1024);\n",
        "    }\n",
        "    b = a;\n",
        "    cerr << \"GENERATE OK!\" << a.size() << endl;\n",
        "\n",
        "    double st = clock();\n",
        "    cout << debubble(a) << endl;\n",
        "    double ed = clock();\n",
        "    std::cout << (ed - st) / CLOCKS_PER_SEC << std::endl;\n",
        "\n",
        "    // for(int i = 0; i < 10; i++) cout << a[i] << endl;\n",
        "\n",
        "    st = clock();\n",
        "    for(int x : b) if(x != 0) c.emplace_back(x);\n",
        "    while(c.size() < b.size()) c.emplace_back(0);\n",
        "\n",
        "    ed = clock();\n",
        "    std::cout << (ed - st) / CLOCKS_PER_SEC << std::endl;\n",
        "    for(int i = 0; i < N; i++) if(a[i] != c[i]) {\n",
        "        cout << i << \" \" << a[i] << \" \" << c[i] << endl;\n",
        "        break;\n",
        "    }\n",
        "\n",
        "    cout << a.size() << \" \" << c.size() << endl;\n",
        "    assert(a == c);\n",
        "    return 0;\n",
        "}\n",
        "/*GENERATE OK!536870912\n",
        "8192 32\n",
        "536347455\n",
        "1.34073\n",
        "28.7449\n",
        "536870912 536870912\n",
        "*/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMoGSdRuXIXu",
        "outputId": "ef9639d8-f1c3-46b9-926f-1339418b2db2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GENERATE OK!536870912\n",
            "4096 16\n",
            "536345938\n",
            "1.44263\n",
            "28.5526\n",
            "536870912 536870912\n",
            "\n"
          ]
        }
      ]
    }
  ]
}